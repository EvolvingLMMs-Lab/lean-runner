{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<ul> <li> <p> Plug &amp; Play</p> <p>Get started in minutes with  Docker's one-click server setup. Our intuitive client abstracts away complex implementation details, letting you focus on what matters\u2014your Lean proofs.</p> </li> <li> <p> High Performance</p> <p>Leverages REPL-based atomized execution with fully asynchronous, multi-threaded architecture to maximize CPU utilization and throughput. Efficient interaction with the client using  FastAPI.</p> </li> <li> <p> Robust &amp; Reliable</p> <p>Persistent  SQLite logging ensures your work is never lost. Built-in crash recovery and automatic retry mechanisms eliminate the frustration of interrupted workflows.</p> </li> <li> <p> Flexible Access Patterns</p> <p>Choose between synchronous and asynchronous clients depending on your use case, from interactive development to large-scale batch processing.</p> </li> <li> <p> Smart Caching</p> <p>Intelligent content-based hashing ensures identical Lean code is processed only once, dramatically reducing computation time for repeated operations.</p> </li> <li> <p> Data Export &amp; Visualization (Soon)</p> <p>Easily export data in various formats (Hugging Face, JSON, XML, Arrow, Parquet) and visualize queries with a simple CLI.</p> </li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>Lean-Runner leverages a powerful Server-Client architecture that smartly places all the complex configuration on the server side, while keeping the client implementation elegantly minimal. We've packaged the entire server using  Docker, making deployment incredibly straightforward and hassle-free.</p> <p></p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@misc{fanyi2025leanrunner,\n    title={Lean-Runner: Deploying High-Performance Lean 4 Server in One Click},\n    author={Fanyi Pu, Oscar Qian, Jinghao Guo, Bo Li},\n    year={2025},\n    publisher={GitHub},\n    howpublished={\\url{https://github.com/EvolvingLMMs-Lab/lean-runner}},\n}\n</code></pre>"},{"location":"quick-start/","title":"Quick Start","text":""},{"location":"quick-start/#server","title":"Server","text":"<p>Docker Engine Required</p> <p>Run the Lean-Runner server using Docker. If Docker is not installed, follow this tutorial to install it.</p> <p>For existing users, pull the latest image to ensure you have the most recent version.</p> <pre><code>docker pull pufanyi/lean-server:latest\n</code></pre> <p>Start the server with a single <code>docker run</code> command:</p> <pre><code>PORT=8080\nCONCURRENCY=32\nDB_PATH=./lean_server.db\n\ndocker run --rm -it \\\n    -p $PORT:8000 \\\n    -v $DB_PATH:/app/lean_server.db \\\n    pufanyi/lean-server:latest \\\n    /app/lean-runner/.venv/bin/lean-server --concurrency=$CONCURRENCY\n</code></pre>"},{"location":"quick-start/#client","title":"Client","text":"<p>Install the Lean-Runner client from PyPI:</p> pipuv <pre><code>pip install lean-runner\n</code></pre> <pre><code>uv pip install lean-runner\n</code></pre> <p>Use <code>LeanClient</code> to verify a proof. The client supports both synchronous and asynchronous operations:</p> <p>Lean proof verification</p> SynchronousAsynchronous <pre><code>from lean_runner import LeanClient\n\n# Define a simple Lean 4 proof\nproof = \"\"\"\\\nimport Mathlib.Tactic.NormNum\ntheorem test : 2 + 2 = 4 := by norm_num\n\"\"\"\n\n# Create client and verify the proof\nwith LeanClient(base_url=\"http://localhost:8080\") as client:\n    result = client.verify(proof=proof)\n    print(result)\n</code></pre> <pre><code>import asyncio\nfrom lean_runner import AsyncLeanClient\n\n# Define a simple Lean 4 proof\nproof = \"\"\"\\\nimport Mathlib.Tactic.NormNum\ntheorem test : 2 + 2 = 4 := by norm_num\n\"\"\"\n\nasync def main():\n    # Create async client and verify the proof\n    async with AsyncLeanClient(base_url=\"http://localhost:8080\") as client:\n        result = await client.verify(proof=proof)\n        print(result)\n\nasyncio.run(main())\n</code></pre>"},{"location":"client/","title":"Client Library Overview","text":"<p>Welcome to the <code>lean-runner</code> client library documentation. This library provides a powerful and flexible Python interface for interacting with the Lean Runner server, allowing you to programmatically verify Lean proofs.</p> <p>The client is designed to be intuitive and supports both simple synchronous operations and high-performance asynchronous workflows, making it suitable for a wide range of applications, from simple scripts to complex, concurrent systems.</p>"},{"location":"client/#getting-started","title":"Getting Started","text":"<p>First, make sure you have the library installed. If not, head over to the installation guide.</p> <ul> <li>Installation: How to install the client library using <code>pip</code> or from source.</li> </ul>"},{"location":"client/#core-features","title":"Core Features","text":"<p>The client library offers several ways to verify proofs, catering to different needs.</p> <ul> <li> <p>Simple Query: The most straightforward way to verify a single proof. The <code>verify</code> method sends a proof and waits for the result, making it perfect for quick checks and simple use cases.</p> </li> <li> <p>Asynchronous Submission and Retrieval: Ideal for long-running proofs. The <code>submit</code> method sends a proof to the server and immediately returns a job ID. You can then use the <code>get_result</code> method to fetch the outcome at a later time, without blocking your application.</p> </li> <li> <p>Bulk Verification: The most efficient way to handle a large number of proofs. The <code>verify_all</code> method processes an entire collection of proofs concurrently, yielding results as they become available. This is highly recommended for batch processing tasks.</p> </li> </ul>"},{"location":"client/#customization","title":"Customization","text":"<p>You can fine-tune the verification process to get the exact information you need.</p> <ul> <li>Proof Configuration: Learn how to use the <code>ProofConfig</code> object to control aspects of the verification, such as enabling Abstract Syntax Tree (AST) output, collecting tactics, and setting timeouts.</li> </ul>"},{"location":"client/#sync-vs-async","title":"Sync vs. Async","text":"<p>All features are available in two flavors:</p> <ul> <li><code>LeanClient</code>: A synchronous client that is easy to use and works well in standard Python scripts.</li> <li><code>AsyncLeanClient</code>: An asynchronous client built on <code>httpx</code> and <code>asyncio</code> for high-performance, non-blocking I/O. It's the best choice for concurrent applications.</li> </ul> <p>Each guide provides examples for both clients, so you can choose the one that best fits your programming style.</p>"},{"location":"client/config/","title":"Proof Configuration","text":"<p>The <code>ProofConfig</code> object allows you to customize the behavior of the proof verification process. Here are the available options:</p> <ul> <li><code>all_tactics: bool</code> (default: <code>False</code>)<ul> <li>If <code>True</code>, the server will return all tactics executed during the proof, including those from imported libraries.</li> </ul> </li> <li><code>ast: bool</code> (default: <code>False</code>)<ul> <li>If <code>True</code>, the server will include the Abstract Syntax Tree (AST) of the proof in the result.</li> </ul> </li> <li><code>tactics: bool</code> (default: <code>False</code>)<ul> <li>If <code>True</code>, the server will return the tactics used in the main proof.</li> </ul> </li> <li><code>premises: bool</code> (default: <code>False</code>)<ul> <li>If <code>True</code>, the server will return the premises (dependencies) of the proof.</li> </ul> </li> <li><code>timeout: float</code> (default: <code>300.0</code>)<ul> <li>The maximum time in seconds to wait for the proof verification to complete.</li> </ul> </li> </ul>"},{"location":"client/install/","title":"Installation","text":""},{"location":"client/install/#install-via-pypi","title":"Install via PyPI","text":"<p><code>lean-runner</code> is available on PyPI. This is the recommended installation method for most users.</p>  uv pip <pre><code>uv pip install lean-runner\n</code></pre> <pre><code>pip install lean-runner\n</code></pre>"},{"location":"client/install/#build-from-source","title":"Build from Source","text":"<p>If you want to try out the latest features or contribute to development, you can install from source.</p>  uv pip <pre><code>git clone https://github.com/EvolvingLMMs-Lab/LeanRunner.git\ncd LeanRunner\nuv pip install -e packages/client\n</code></pre> <pre><code>git clone https://github.com/EvolvingLMMs-Lab/LeanRunner.git\ncd LeanRunner\npip install -e packages/client\n</code></pre>"},{"location":"client/simple-query/","title":"Simple Query","text":"<p>This guide will walk you through performing a simple proof verification using both synchronous and asynchronous clients.</p>"},{"location":"client/simple-query/#synchronous-client","title":"Synchronous Client","text":"<p>The synchronous client is straightforward to use and is suitable for most common use cases.</p>"},{"location":"client/simple-query/#api-reference-verify","title":"API Reference: <code>verify</code>","text":"<p>The <code>client.verify()</code> method sends a proof to the server and synchronously waits for the verification result.</p> <p>Function Signature</p> <pre><code>def verify(\n    self,\n    proof: str | Path | os.PathLike,\n    config: ProofConfig | None = None\n) -&gt; ProofResult:\n</code></pre>"},{"location":"client/simple-query/#parameters","title":"Parameters","text":"<ul> <li> <p><code>proof</code> (<code>str | Path | os.PathLike</code>): The proof to be verified. This can be provided in several ways:</p> <ul> <li>A string containing the Lean code.</li> <li>A <code>pathlib.Path</code> object pointing to a <code>.lean</code> file.</li> <li>A string representing the path to a <code>.lean</code> file.</li> </ul> </li> <li> <p><code>config</code> (<code>ProofConfig | None</code>, optional): A configuration object to customize the verification process. If not provided, default settings are used. See the Proof Configuration page for details on available options.</p> </li> </ul>"},{"location":"client/simple-query/#returns","title":"Returns","text":"<ul> <li><code>ProofResult</code>: A Pydantic model containing the verification results, including status, and any potential errors.</li> </ul>"},{"location":"client/simple-query/#example","title":"Example","text":"<p>Verifying a proof</p> <p>Here's how to verify a simple proof using the <code>LeanClient</code>:</p> <p><pre><code>from lean_runner import LeanClient\n\n# Initialize the client with the server's base URL\nclient = LeanClient(\"http://localhost:8000\")\n\n# Define the proof as a string\nproof_content = (\n    \"import Mathlib.Tactic.NormNum\\n\"\n    \"theorem test : 2 + 2 = 4 := by norm_num\"\n)\n\n# Verify the proof\nresult = client.verify(proof_content)\n\n# Print the result\nprint(result.model_dump_json(indent=4))\n\n# The client should be closed when no longer needed\nclient.close()\n</code></pre> <pre><code>{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n</code></pre> </p> <p>Using a <code>with</code> statement</p> <p>You can use a <code>with</code> statement to manage the client's lifecycle automatically:</p> <p><pre><code>from lean_runner import LeanClient\n\nwith LeanClient(\"http://localhost:8000\") as client:\n    proof_content = (\n        \"import Mathlib.Tactic.NormNum\\n\"\n        \"theorem test : 2 + 2 = 4 := by norm_num\"\n    )\n    result = client.verify(proof_content)\n    print(result.model_dump_json(indent=4))\n</code></pre> <pre><code>{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n</code></pre> </p>"},{"location":"client/simple-query/#asynchronous-client","title":"Asynchronous Client","text":"<p>The asynchronous client is ideal for applications that require high concurrency and non-blocking I/O.</p>"},{"location":"client/simple-query/#api-reference-verify_1","title":"API Reference: <code>verify</code>","text":"<p>The <code>client.verify()</code> method sends a proof to the server and asynchronously awaits the verification result.</p> <p>Function Signature</p> <pre><code>async def verify(\n    self,\n    proof: str | Path | os.PathLike | AnyioPath,\n    config: ProofConfig | None = None,\n) -&gt; ProofResult:\n</code></pre>"},{"location":"client/simple-query/#parameters_1","title":"Parameters","text":"<ul> <li> <p><code>proof</code> (<code>str | Path | os.PathLike | AnyioPath</code>): The proof to be verified. This can be provided as:</p> <ul> <li>A string containing the Lean code.</li> <li>A <code>pathlib.Path</code> or <code>anyio.Path</code> object pointing to a <code>.lean</code> file.</li> <li>A string representing the path to a <code>.lean</code> file.</li> </ul> </li> <li> <p><code>config</code> (<code>ProofConfig | None</code>, optional): A configuration object to customize the verification process. If not provided, default settings are used. See the Proof Configuration page for details on available options.</p> </li> </ul>"},{"location":"client/simple-query/#returns_1","title":"Returns","text":"<ul> <li><code>ProofResult</code>: A Pydantic model containing the verification results.</li> </ul>"},{"location":"client/simple-query/#example_1","title":"Example","text":"<p>Verifying a proof asynchronously</p> <p>Here's the same example using the <code>AsyncLeanClient</code>:</p> <p><pre><code>import asyncio\nfrom lean_runner import AsyncLeanClient\n\nasync def main():\n    # Initialize the async client\n    async with AsyncLeanClient(\"http://localhost:8000\") as client:\n        proof_content = (\n            \"import Mathlib.Tactic.NormNum\\n\"\n            \"theorem test : 2 + 2 = 4 := by norm_num\"\n        )\n        result = await client.verify(proof_content)\n        print(result.model_dump_json(indent=4))\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n</code></pre> </p> <p>In this example, <code>async with</code> ensures the client session is properly closed. The <code>await client.verify()</code> call performs the verification without blocking the event loop.</p>"},{"location":"client/submit-get-result/","title":"Asynchronous Submission and Retrieval","text":"<p>This guide covers the process of submitting a proof for verification without waiting for the result, and then retrieving the result later. This is useful for long-running proofs or for integrating into job queue systems.</p>"},{"location":"client/submit-get-result/#synchronous-client","title":"Synchronous Client","text":"<p>The synchronous client allows you to submit a proof and then poll for the result at a later time.</p>"},{"location":"client/submit-get-result/#api-reference-submit-and-get_result","title":"API Reference: <code>submit</code> and <code>get_result</code>","text":"<p>First, <code>client.submit()</code> sends a proof to the server and returns a <code>Proof</code> object, which acts as a handle for the verification job. Then, <code>client.get_result()</code> uses this handle to fetch the result.</p> <p>Function Signatures</p> <pre><code>def submit(\n    self,\n    proof: str | Path | os.PathLike,\n    config: ProofConfig | None = None\n) -&gt; Proof:\n\ndef get_result(self, proof: Proof) -&gt; ProofResult:\n</code></pre>"},{"location":"client/submit-get-result/#parameters","title":"Parameters","text":"<ul> <li><code>submit.proof</code> (<code>str | Path | os.PathLike</code>): The proof content to be verified (string, <code>pathlib.Path</code>, or path string).</li> <li><code>submit.config</code> (<code>ProofConfig | None</code>, optional): Configuration for the verification. See Proof Configuration for details.</li> <li><code>get_result.proof</code> (<code>Proof</code>): The <code>Proof</code> object returned by the <code>submit</code> method.</li> </ul>"},{"location":"client/submit-get-result/#returns","title":"Returns","text":"<ul> <li><code>submit</code>: Returns a <code>Proof</code> object containing metadata about the submitted job, including its unique ID.</li> <li><code>get_result</code>: Returns a <code>ProofResult</code> object with the full verification result.</li> </ul>"},{"location":"client/submit-get-result/#example","title":"Example","text":"<p>Submitting a proof and getting the result</p> <p>The following example shows how to submit a proof and then retrieve its result. Note that in a real-world application, you might add a delay or a retry mechanism between submission and result retrieval.</p> <p><pre><code>import time\nfrom lean_runner import LeanClient\n\nwith LeanClient(\"http://localhost:8000\") as client:\n    proof_content = (\n        \"import Mathlib.Tactic.NormNum\\n\"\n        \"theorem test : 2 + 2 = 4 := by norm_num\"\n    )\n\n    # Submit the proof\n    submitted_proof = client.submit(proof_content)\n    print(f\"Proof submitted with ID: {submitted_proof.id}\")\n\n    # Retrieve the result later\n    # In a real scenario, you might wait here\n    result = client.get_result(submitted_proof)\n    print(result.model_dump_json(indent=4))\n\n    time.sleep(1)\n\n    result = client.get_result(submitted_proof)\n    print(result.model_dump_json(indent=4))\n</code></pre> <pre><code>Proof submitted with ID: 019894b0-554f-76e0-93db-0df8e92271ab\n{\n    \"success\": null,\n    \"status\": \"pending\",\n    \"result\": null,\n    \"error_message\": null\n}\n{\n    \"success\": null,\n    \"status\": \"running\",\n    \"result\": null,\n    \"error_message\": null\n}\n{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n</code></pre> </p>"},{"location":"client/submit-get-result/#asynchronous-client","title":"Asynchronous Client","text":"<p>The asynchronous client provides non-blocking methods to submit a proof and fetch its result, making it ideal for highly concurrent applications.</p>"},{"location":"client/submit-get-result/#api-reference-submit-and-get_result_1","title":"API Reference: <code>submit</code> and <code>get_result</code>","text":"<p>The <code>client.submit()</code> coroutine sends the proof, and <code>client.get_result()</code> fetches the outcome.</p> <p>Function Signatures</p> <pre><code>async def submit(\n    self,\n    proof: str | Path | os.PathLike | AnyioPath,\n    config: ProofConfig | None = None,\n) -&gt; Proof:\n\nasync def get_result(self, proof: Proof) -&gt; ProofResult:\n</code></pre>"},{"location":"client/submit-get-result/#parameters_1","title":"Parameters","text":"<ul> <li><code>submit.proof</code> (<code>str | Path | os.PathLike | AnyioPath</code>): The proof content (string, <code>pathlib.Path</code>, <code>anyio.Path</code>, or path string).</li> <li><code>submit.config</code> (<code>ProofConfig | None</code>, optional): Verification configuration. See Proof Configuration.</li> <li><code>get_result.proof</code> (<code>Proof</code>): The <code>Proof</code> object returned by <code>submit</code>.</li> </ul>"},{"location":"client/submit-get-result/#returns_1","title":"Returns","text":"<ul> <li><code>submit</code>: A <code>Proof</code> object.</li> <li><code>get_result</code>: A <code>ProofResult</code> object.</li> </ul>"},{"location":"client/submit-get-result/#example_1","title":"Example","text":"<p>Asynchronous submit and retrieve</p> <p>This example demonstrates the async workflow.</p> <p><pre><code>import asyncio\nfrom lean_runner import AsyncLeanClient\n\nasync def main():\n    async with AsyncLeanClient(\"http://localhost:8000\") as client:\n        proof_content = (\n            \"import Mathlib.Tactic.NormNum\\n\"\n            \"theorem test : 2 + 2 = 4 := by norm_num\"\n        )\n\n        # Submit the proof without blocking\n        submitted_proof = await client.submit(proof_content)\n        print(f\"Proof submitted with ID: {submitted_proof.id}\")\n\n        result = await client.get_result(submitted_proof)\n        print(result.model_dump_json(indent=4))\n\n        # Wait and retrieve the result\n        await asyncio.sleep(1) # Simulate waiting\n        result = await client.get_result(submitted_proof)\n        print(result.model_dump_json(indent=4))\n\n        await asyncio.sleep(1)\n        result = await client.get_result(submitted_proof)\n        print(result.model_dump_json(indent=4))\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>Proof submitted with ID: 019894b2-bf2b-77b1-9f82-774234ce1ea8\n{\n    \"success\": null,\n    \"status\": \"pending\",\n    \"result\": null,\n    \"error_message\": null\n}\n{\n    \"success\": null,\n    \"status\": \"running\",\n    \"result\": null,\n    \"error_message\": null\n}\n{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n</code></pre> </p>"},{"location":"client/verify-all/","title":"Bulk Verification","text":"<p>This guide explains how to verify multiple proofs efficiently in a single batch operation using the <code>verify_all</code> method.</p>"},{"location":"client/verify-all/#synchronous-client","title":"Synchronous Client","text":"<p>The synchronous <code>verify_all</code> method is ideal for processing a collection of proofs when you want to handle them concurrently without the complexity of async programming. It uses a thread pool to manage concurrent requests.</p>"},{"location":"client/verify-all/#api-reference-verify_all","title":"API Reference: <code>verify_all</code>","text":"<p>The <code>client.verify_all()</code> method sends a collection of proofs to the server and yields results as they are completed. This approach is memory-efficient as it doesn't wait for all proofs to be verified before returning results.</p> <p>Function Signature</p> <pre><code>def verify_all(\n    self,\n    proofs: Iterable[str | Path | os.PathLike],\n    config: ProofConfig | None = None,\n    total: int | None = None,\n    max_workers: int = 128,\n    progress_bar: bool = True,\n) -&gt; Iterable[ProofResult]:\n</code></pre>"},{"location":"client/verify-all/#parameters","title":"Parameters","text":"<ul> <li><code>proofs</code> (<code>Iterable[str | Path | os.PathLike]</code>): An iterable of proofs to be verified. Each item can be:<ul> <li>A string containing Lean code.</li> <li>A <code>pathlib.Path</code> object to a <code>.lean</code> file.</li> <li>A string path to a <code>.lean</code> file.</li> </ul> </li> <li><code>config</code> (<code>ProofConfig | None</code>, optional): Configuration for the verification process. See the Proof Configuration for details.</li> <li><code>total</code> (<code>int | None</code>, optional): The total number of proofs. If not provided, it's inferred if <code>proofs</code> has a <code>__len__</code> method.</li> <li><code>max_workers</code> (<code>int</code>): The maximum number of concurrent threads to use.</li> <li><code>progress_bar</code> (<code>bool</code>): If <code>True</code>, a progress bar is displayed.</li> </ul>"},{"location":"client/verify-all/#returns","title":"Returns","text":"<ul> <li><code>Iterable[ProofResult]</code>: An iterator that yields <code>ProofResult</code> objects as each verification completes.</li> </ul>"},{"location":"client/verify-all/#example","title":"Example","text":"<p>Verifying a list of proofs</p> <p>Here's how to verify a list of proofs concurrently.</p> <p><pre><code>from lean_runner import LeanClient\n\nwith LeanClient(\"http://localhost:8000\") as client:\n    proofs = [\n        (\n            \"import Mathlib.Tactic.NormNum\\n\" \\\n            \"theorem test1 : 2 + 2 = 4 := by norm_num\"\n        ),\n        (\n            \"import Mathlib.Tactic.NormNum\\n\" \\\n            \"theorem test2 : 2 + 2 = 4 := by norm_num\"\n        ),\n        (\n            \"import Mathlib.Tactic.NormNum\\n\" \\\n            \"theorem test3 : 2 + 2 = 4 := by norm_num\"\n        ),\n    ]\n\n    results = client.verify_all(proofs)\n\n    for result in results:\n        print(result.model_dump_json(indent=4))\n</code></pre> <pre><code>{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n</code></pre>"},{"location":"client/verify-all/#asynchronous-client","title":"Asynchronous Client","text":"<p>The asynchronous <code>verify_all</code> method offers the highest performance for I/O-bound tasks, making it perfect for applications with high concurrency needs.</p>"},{"location":"client/verify-all/#api-reference-verify_all_1","title":"API Reference: <code>verify_all</code>","text":"<p>The <code>client.verify_all()</code> coroutine processes an iterable (or async iterable) of proofs, using an efficient producer-consumer pattern to manage the workload.</p> <p>Function Signature</p> <pre><code>async def verify_all(\n    self,\n    proofs: Iterable[str | Path | os.PathLike | AnyioPath]\n    | AsyncIterable[str | Path | os.PathLike | AnyioPath],\n    config: ProofConfig | None = None,\n    total: int | None = None,\n    max_workers: int = 128,\n    progress_bar: bool = True,\n) -&gt; AsyncIterable[ProofResult]:\n</code></pre>"},{"location":"client/verify-all/#parameters_1","title":"Parameters","text":"<ul> <li><code>proofs</code> (<code>Iterable | AsyncIterable</code>): An iterable or async iterable of proofs. Each item can be:<ul> <li>A string of Lean code.</li> <li>A <code>pathlib.Path</code> or <code>anyio.Path</code> to a <code>.lean</code> file.</li> <li>A string path to a <code>.lean</code> file.</li> </ul> </li> <li><code>config</code> (<code>ProofConfig | None</code>, optional): Verification configuration. See Proof Configuration.</li> <li><code>total</code> (<code>int | None</code>, optional): The total number of proofs for the progress bar.</li> <li><code>max_workers</code> (<code>int</code>): The maximum number of concurrent async tasks.</li> <li><code>progress_bar</code> (<code>bool</code>): If <code>True</code>, a progress bar is shown.</li> </ul>"},{"location":"client/verify-all/#returns_1","title":"Returns","text":"<ul> <li><code>AsyncIterable[ProofResult]</code>: An async iterator that yields <code>ProofResult</code> objects as they complete.</li> </ul>"},{"location":"client/verify-all/#example_1","title":"Example","text":"<p>Verifying proofs asynchronously</p> <p>The <code>async for</code> loop is used to iterate over the results from the async generator.</p> <p><pre><code>import asyncio\nfrom lean_runner import AsyncLeanClient\n\nasync def main():\n    async with AsyncLeanClient(\"http://localhost:8000\") as client:\n        proofs = [\n            (\n                \"import Mathlib.Tactic.NormNum\\n\"\n                \"theorem test1 : 2 + 2 = 4 := by norm_num\"\n            ),\n            (\n                \"import Mathlib.Tactic.NormNum\\n\"\n                \"theorem test2 : 2 + 2 = 4 := by norm_num\"\n            ),\n            (\n                \"import Mathlib.Tactic.NormNum\\n\"\n                \"theorem test3 : 2 + 2 = 4 := by norm_num\"\n            ),\n        ]\n\n        results = client.verify_all(proofs)\n\n        async for result in results:\n            print(result.model_dump_json(indent=2))\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <pre><code>{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n</code></pre> </p>"},{"location":"dev/docs/","title":"API Documentation","text":"<p>This section contains the detailed API documentation for the <code>lean-runner</code> packages.</p>"},{"location":"dev/docs/#client-api","title":"Client API","text":"<p>The client library provides a simple and efficient way to interact with the Lean server.</p> <p> View the Client API Reference</p>"},{"location":"dev/docs/#server-api","title":"Server API","text":"<p>The server provides the core functionality for running Lean proofs and managing results.</p> <p> View the Server API Reference</p>"},{"location":"dev/todos/","title":"Development Roadmap","text":"<p>This page documents the development roadmap and planned features for Lean Server.</p> <ul> <li> Custom Mathlib Support in Docker<ul> <li>Support for using custom <code>mathlib</code> versions within Docker containers</li> <li>This would allow users to specify different Mathlib versions for their proofs without rebuilding the entire Docker image</li> <li>Currently, the server uses a fixed Mathlib version ( v4.22.0-rc4) bundled in the Docker image</li> </ul> </li> <li> <code>config.yaml</code> file support for Docker server</li> <li> Lean Output Result Processing<ul> <li> Parse related results</li> <li> Support proof simplification</li> </ul> </li> <li> Data Export Capabilities<ul> <li> Hugging Face Datasets</li> <li> JSON / JSONL</li> <li>  CSV</li> <li>  Excel</li> <li> Parquet</li> <li> Arrow</li> </ul> </li> <li> Data Visualization</li> <li> Docker Layer Optimization<ul> <li>Optimize Docker image layering to make <code>docker pull</code> operations faster</li> <li>This will reduce download time when updating to newer versions of the server</li> <li>Current users need to pull the entire image even for small updates</li> </ul> </li> </ul>"},{"location":"server/api/","title":"API Reference","text":"<p>This document provides a comprehensive reference for all RESTful API endpoints available in the Lean Prover Server.</p> <p>Base URL</p> <p>All API endpoints are relative to your server's base URL (e.g., <code>http://localhost:8000</code>).</p>"},{"location":"server/api/#endpoints","title":"Endpoints","text":""},{"location":"server/api/#health-check","title":"Health Check","text":""},{"location":"server/api/#get-health","title":"<code>GET /health</code>","text":"<p>Verifies the server's operational status and retrieves basic information.</p> <p>Responses - <code>200 OK</code>: Server is running. - <code>500 Internal ServerError</code>: Server-side processing error.</p> <p>Success Response <code>200 OK</code> <pre><code>{\n  \"status\": \"ok\",\n  \"message\": \"Lean Server is running\",\n  \"version\": \"0.0.1\"\n}\n</code></pre></p> <p>cURL Example <pre><code>curl \"http://localhost:8000/health\"\n</code></pre></p>"},{"location":"server/api/#proof-verification","title":"Proof Verification","text":""},{"location":"server/api/#post-provecheck","title":"<code>POST /prove/check</code>","text":"<p>Synchronously verifies a Lean proof for correctness.</p> <p>Content-Type</p> <p>This endpoint requires <code>application/x-www-form-urlencoded</code>.</p> <p>Parameters</p> Parameter Type Required Default Description <code>proof</code> <code>string</code> Yes - The Lean proof code to check. <code>config</code> <code>string</code> No <code>{}</code> A JSON string to configure the proof checking process. See Proof Configuration for details. <p>Responses - <code>200 OK</code>: Verification finished. - <code>500 Internal Server Error</code>: Server-side processing error.</p> <p>Success Response <code>200 OK</code> <pre><code>{\n  \"success\": true,\n  \"status\": \"finished\",\n  \"result\": { ... },\n  \"error_message\": null\n}\n</code></pre></p> <p>cURL Example <pre><code>curl -X POST \"http://localhost:8000/prove/check\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"proof=theorem test : 1 + 1 = 2 := by norm_num\" \\\n  -d \"config={}\"\n</code></pre></p> <p>Python Example <pre><code>import requests\nimport json\n\nresponse = requests.post(\n    \"http://localhost:8000/prove/check\",\n    data={\n        \"proof\": \"theorem test : 1 + 1 = 2 := by norm_num\",\n        \"config\": json.dumps({\"timeout\": 600.0})\n    }\n)\nprint(response.json())\n</code></pre></p>"},{"location":"server/api/#post-provesubmit","title":"<code>POST /prove/submit</code>","text":"<p>Submits a Lean proof for asynchronous processing and returns a unique <code>proof_id</code>.</p> <p>Asynchronous Processing</p> <p>Use <code>GET /prove/result/{proof_id}</code> to retrieve the verification result later.</p> <p>Parameters</p> Parameter Type Required Default Description <code>proof</code> <code>string</code> Yes - The Lean proof code to submit. <code>config</code> <code>string</code> No <code>{}</code> A JSON string to configure the proof checking process. See Proof Configuration for details. <p>Responses - <code>200 OK</code>: Proof submitted successfully. - <code>502 Bad Gateway</code>: Error during proof submission.</p> <p>Success Response <code>200 OK</code> <pre><code>{\n  \"proof_id\": \"your-unique-proof-id\"\n}\n</code></pre></p> <p>cURL Example <pre><code>curl -X POST \"http://localhost:8000/prove/submit\" \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"proof=theorem hard_proof : some_complex_statement := by sorry\" \\\n  -d 'config={\"timeout\": 900.0}'\n</code></pre></p> <p>Python Example <pre><code>import requests\nimport json\n\nresponse = requests.post(\n    \"http://localhost:8000/prove/submit\",\n    data={\n        \"proof\": \"theorem complex_proof : some_statement := by tactic_sequence\",\n        \"config\": json.dumps({\"timeout\": 900.0})\n    }\n)\nproof_id = response.json().get(\"proof_id\")\nprint(f\"Submitted proof with ID: {proof_id}\")\n</code></pre></p>"},{"location":"server/api/#get-proveresultproof_id","title":"<code>GET /prove/result/{proof_id}</code>","text":"<p>Retrieves the result of a previously submitted asynchronous proof.</p> <p>Path Parameters</p> Parameter Type Required Description <code>proof_id</code> <code>string</code> Yes The unique ID of the submitted proof. <p>Responses - <code>200 OK</code>: Result retrieved successfully. - <code>404 Not Found</code>: The specified <code>proof_id</code> does not exist. - <code>500 Internal Server Error</code>: Server-side processing error.</p> <p>Success Response <code>200 OK</code> <pre><code>{\n  \"success\": true,\n  \"status\": \"finished\",\n  \"result\": { ... },\n  \"error_message\": null\n}\n</code></pre></p> <p>cURL Example <pre><code>curl \"http://localhost:8000/prove/result/your-proof-id-here\"\n</code></pre></p> <p>Python Example <pre><code>import requests\n\nproof_id = \"your-proof-id-here\"\nresponse = requests.get(f\"http://localhost:8000/prove/result/{proof_id}\")\nprint(response.json())\n</code></pre></p>"},{"location":"server/api/#database-management","title":"Database Management","text":""},{"location":"server/api/#get-dbfetch","title":"<code>GET /db/fetch</code>","text":"<p>Fetches records from the database using an SQL query and streams the results.</p> <p>Streaming Response</p> <p>This endpoint returns a streaming JSON response with a <code>Content-Disposition: attachment</code> header, making it suitable for large datasets.</p> <p>Query Parameters</p> Parameter Type Required Default Description <code>query</code> <code>string</code> No <code>SELECT * FROM proof</code> The SQL query to execute. <code>batch_size</code> <code>integer</code> No <code>100</code> The number of records to fetch per batch. <p>Responses - <code>200 OK</code>: Query executed successfully. - <code>500 Internal Server Error</code>: Database error.</p> <p>cURL Example <pre><code>curl \"http://localhost:8000/db/fetch?query=SELECT * FROM proof LIMIT 10&amp;batch_size=5\"\n</code></pre></p> <p>Python Example <pre><code>import requests\n\nresponse = requests.get(\n    \"http://localhost:8000/db/fetch\",\n    params={\n        \"query\": \"SELECT * FROM proof WHERE created_at &gt; '2025-01-01'\",\n        \"batch_size\": 50\n    },\n    stream=True\n)\n\nfor chunk in response.iter_content(chunk_size=1024):\n    if chunk:\n        print(chunk.decode('utf-8'))\n</code></pre></p>"},{"location":"server/api/#delete-dbclean","title":"<code>DELETE /db/clean</code>","text":"<p>Cleans the database by removing proof records older than a specified time.</p> <p>Query Parameters</p> Parameter Type Required Default Description <code>seconds</code> <code>integer</code> No <code>0</code> Removes records older than this many seconds. <p>Responses - <code>200 OK</code>: Database cleaned successfully. - <code>500 Internal Server Error</code>: Database error.</p> <p>Success Response <code>200 OK</code> <pre><code>{\n  \"message\": \"Database cleaned successfully\"\n}\n</code></pre></p> <p>cURL Example <pre><code># Clean records older than 1 hour (3600 seconds)\ncurl -X DELETE \"http://localhost:8000/db/clean?seconds=3600\"\n</code></pre></p> <p>Python Example <pre><code>import requests\n\n# Clean records older than 24 hours (86400 seconds)\nresponse = requests.delete(\n    \"http://localhost:8000/db/clean\",\n    params={\"seconds\": 86400}\n)\nprint(response.json())\n</code></pre></p>"},{"location":"server/api/#data-structures","title":"Data Structures","text":""},{"location":"server/api/#proof-configuration","title":"Proof Configuration","text":"<p>The <code>config</code> parameter is a JSON string used to customize proof verification.</p> <p>Default Configuration <pre><code>{\n  \"timeout\": 300.0,\n  \"all_tactics\": false,\n  \"tactics\": false,\n  \"ast\": false,\n  \"premises\": false\n}\n</code></pre></p> <p>Options</p> Option Type Default Description <code>timeout</code> <code>float</code> <code>300.0</code> Maximum processing time in seconds. <code>all_tactics</code> <code>boolean</code> <code>false</code> Include all tactics in the proof result. <code>tactics</code> <code>boolean</code> <code>false</code> Include tactics information in the result. <code>ast</code> <code>boolean</code> <code>false</code> Include the abstract syntax tree in the result. <code>premises</code> <code>boolean</code> <code>false</code> Include premises information in the result."},{"location":"server/api/#proof-result","title":"Proof Result","text":"<p>The proof verification endpoints (<code>/prove/check</code> and <code>/prove/result/{proof_id}</code>) return a JSON object with the following structure.</p> <p>Result Object <pre><code>{\n  \"success\": true,\n  \"status\": \"finished\",\n  \"result\": {\n    \"tactics\": [],\n    \"ast\": {},\n    \"premises\": []\n  },\n  \"error_message\": null\n}\n</code></pre></p> <p>Fields</p> Field Type Description <code>success</code> <code>boolean</code> <code>true</code> if the proof was successful, otherwise <code>false</code>. <code>status</code> <code>string</code> The current status: <code>pending</code>, <code>running</code>, <code>finished</code>, or <code>error</code>. <code>result</code> <code>object</code> Contains detailed results based on the <code>config</code> options. <code>error_message</code> <code>string</code> An error message if the <code>status</code> is <code>error</code>."},{"location":"server/api/#error-handling","title":"Error Handling","text":"<p>API errors are returned in a consistent JSON format.</p> <p>Error Response <pre><code>{\n  \"detail\": \"A descriptive error message.\"\n}\n</code></pre></p> <p>Common Status Codes</p> Code Description Reason <code>400</code> Bad Request Invalid parameters or malformed request body. <code>404</code> Not Found The requested resource (e.g., a <code>proof_id</code>) does not exist. <code>500</code> Internal Server Error An unexpected error occurred on the server. <code>502</code> Bad Gateway The server encountered an error with an external service."},{"location":"server/config/","title":"Configuration","text":"<p>The Lean Runner server can be configured through both command-line arguments and a YAML configuration file. Command-line arguments will always take precedence over the configuration file.</p>"},{"location":"server/config/#command-line-arguments","title":"Command-line Arguments","text":"<p>You can launch the server with the following command-line arguments:</p> Argument Default Value Description <code>--host</code> <code>0.0.0.0</code> The host to bind the server to. <code>--port</code> <code>8000</code> The port to run the server on. <code>--concurrency</code> <code>32</code> Maximum number of concurrent Lean worker threads. <code>--config</code> <code>default</code> Path to a custom YAML configuration file. If not provided, the default configuration is used. <code>--lean-workspace</code> <code>default</code> Path to the Lean workspace. Overrides the <code>workspace</code> value in the config file. <code>--log-level</code> <code>INFO</code> Set the logging level. Options: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITICAL</code>."},{"location":"server/config/#configuration-file","title":"Configuration File","text":"<p>You can also use a YAML file to configure the server. By default, the server looks for <code>default_config.yaml</code>. You can specify a custom configuration file using the <code>--config</code> argument.</p> <p>Info</p> <p>Using a custom configuration file is primarily intended for when you are running the server from the source code. Support for custom configuration files within a Docker environment is on our roadmap and will be implemented in a future release.</p> <p>A custom configuration file will be deeply merged with the default configuration. This means if you don't specify an option in your custom file, the value from <code>default_config.yaml</code> will be used.</p> <p>The configuration is structured into three main sections: <code>lean</code>, <code>sqlite</code>, and <code>logging</code>.</p>"},{"location":"server/config/#lean","title":"<code>lean</code>","text":"<p>This section configures the Lean environment.</p> Key Type Description <code>executable</code> string The absolute path to the <code>lake</code> executable. <code>workspace</code> string The absolute path to the Lean project workspace. <code>concurrency</code> integer The maximum number of concurrent Lean processes. This can be overridden by the <code>--concurrency</code> command-line argument."},{"location":"server/config/#sqlite","title":"<code>sqlite</code>","text":"<p>This section configures the SQLite database connection.</p> Key Type Description <code>database_path</code> string The path to the SQLite database file. <code>timeout</code> integer The connection timeout in seconds."},{"location":"server/config/#logging","title":"<code>logging</code>","text":"<p>This section configures the server's logging behavior using Python's <code>logging.config</code> dictionary schema.</p> <p>Tip</p> <p>You can customize handlers, formatters, and log levels for different parts of the application. For more details, refer to the Python logging documentation.</p>"},{"location":"server/config/#default-configuration","title":"Default Configuration","text":"<p>Here is the default configuration file:</p> packages/server/lean_server/config/default_config.yaml<pre><code>lean:\n  executable: /root/.elan/bin/lake\n  workspace: /app/lean-runner/playground\n  lean_timeout: 300\nsqlite:\n  database_path: /app/lean_server.db\n  timeout: 10\nlogging:\n  version: 1\n  disable_existing_loggers: false\n  handlers:\n    default:\n      class: \"rich.logging.RichHandler\"\n      level: \"INFO\"\n      rich_tracebacks: true\n      tracebacks_word_wrap: false\n  loggers:\n    lean_server:\n      handlers:\n        - \"default\"\n      level: \"INFO\"\n    uvicorn:\n      handlers:\n        - \"default\"\n      level: \"INFO\"\n      propagate: false\n    uvicorn.error:\n      handlers:\n        - \"default\"\n      level: \"INFO\"\n      propagate: false\n    uvicorn.access:\n      handlers:\n        - \"default\"\n      level: \"INFO\"\n      propagate: false\n</code></pre>"},{"location":"server/docker/","title":"Install Lean Server via  Docker","text":"<p>For a hassle-free setup of the Lean Server, we strongly recommend using  Docker. This approach avoids complex local configuration of Lean and its dependencies.</p> <p>The Docker image comes with <code>mathlib</code> version  v4.22.0-rc4. Custom <code>mathlib</code> versions are not currently supported with this method, but we plan to add this feature in the near future. Currenty, if you require a specific version, please refer to the build from source guide.</p> <p>Prerequisites</p> <p>Before you begin, ensure you have Docker installed on your system.</p>"},{"location":"server/docker/#pull-the-docker-image","title":"Pull the Docker Image","text":"<p>First, pull the latest server image from Docker Hub. This ensures you have the most recent version.</p> <pre><code>docker pull pufanyi/lean-server:latest\n</code></pre>"},{"location":"server/docker/#running-the-server","title":"Running the Server","text":"<p>You can run the server in two modes: either as an interactive process in your terminal or as a detached process running in the background.</p>"},{"location":"server/docker/#configuration-parameters","title":"Configuration Parameters","text":"<p>You can configure the server using the following environment variables:</p> <ul> <li><code>PORT</code>: The port on your host machine that will forward to the server's port <code>8000</code> inside the container.</li> <li><code>CONCURRENCY</code>: The number of concurrent requests the server can handle. The optimal value depends on your machine's resources.</li> <li><code>DB_PATH</code> (host): The path to the database file on your host, which is mounted into the container at <code>/app/lean_server.db</code>.</li> </ul>"},{"location":"server/docker/#option-a-interactive-mode-simple-run","title":"Option A: Interactive Mode (Simple Run)","text":"<p>This mode is useful for temporary use or for watching the server logs in real-time. The server will stop when you close your terminal session (by pressing <code>Ctrl+C</code>).</p> <pre><code># Configuration\nPORT=8888\nCONCURRENCY=32\nDB_PATH=./lean_server.db\n\n# Run the container\ndocker run --rm -it \\\n    -p $PORT:8000 \\\n    -v $DB_PATH:/app/lean_server.db \\\n    pufanyi/lean-server:latest \\\n    /app/lean-runner/.venv/bin/lean-server --concurrency=$CONCURRENCY\n</code></pre>"},{"location":"server/docker/#option-b-detached-mode-run-in-background","title":"Option B: Detached Mode (Run in Background)","text":"<p>This is the recommended mode for long-running services. The container will continue to run in the background until explicitly stopped.</p> <pre><code># Configuration\nPORT=8888\nCONCURRENCY=32\nDB_PATH=./lean_server.db\n\n# Run the container\ndocker run -d \\\n    --name lean-server \\\n    -p $PORT:8000 \\\n    -v $DB_PATH:/app/lean_server.db \\\n    pufanyi/lean-server:latest \\\n    /app/lean-runner/.venv/bin/lean-server --concurrency=$CONCURRENCY\n</code></pre> <p>To stop the container, you can use the following command:</p> <pre><code>docker stop lean-server\n</code></pre> <p>To view the logs of the container, you can use the following command:</p> <pre><code>docker logs -f lean-server\n</code></pre> Understanding the Docker Command Flag Description <code>--rm</code> (Interactive Mode) Automatically removes the container when it exits. <code>-it</code> (Interactive Mode) Creates an interactive terminal session. <code>-d</code> (Detached Mode) Runs the container in the background. <code>--name</code> (Detached Mode) Assigns a memorable name to the container (e.g., <code>lean-server</code>). <code>-v</code> Mounts a volume from the host to the container. <code>-p X:Y</code> Maps port <code>X</code> on the host to port <code>Y</code> inside the container. Our server runs on port <code>8000</code> in the container. <p>Check Docker Documentation for more details.</p>"},{"location":"server/docker/#verifying-the-server","title":"Verifying the Server","text":"<p>After starting the container, you can verify that the server is running by sending a health check request. Open a new terminal and run:</p> <pre><code>curl http://localhost:8888/health\n</code></pre> <p>If the server is running correctly, you should receive a response like:</p> <pre><code>{\"status\":\"ok\", \"message\":\"Lean Server is running\", \"version\":\"0.0.1\"}\n</code></pre>"},{"location":"server/docker/#next-steps","title":"Next Steps","text":"<p>After successful installation:</p> <ol> <li>Read the Client Documentation to learn how to interact with the server</li> <li>Explore the API Documentation for detailed endpoint reference</li> </ol>"},{"location":"server/source/","title":"Build Lean Server from Source","text":"<p>This guide walks you through setting up the Lean Server from source code, providing a high-performance REST API for executing and verifying Lean 4 mathematical proofs.</p>"},{"location":"server/source/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have the following installed on your system:</p> <ul> <li> uv or  Conda: We strongly recommend using  uv. You can follow this link for installation.</li> <li>elan: You can follow this tutorial to install elan.</li> </ul>"},{"location":"server/source/#installation-steps","title":"Installation Steps","text":""},{"location":"server/source/#1-clone-the-repository","title":"1. Clone the Repository","text":"<p>Choose your preferred method to clone the repository:</p> <pre><code># Clone using HTTPS\ngit clone https://github.com/EvolvingLMMs-Lab/lean-runner.git\ncd lean-runner\n</code></pre>"},{"location":"server/source/#2-set-up-python-environment","title":"2. Set Up Python Environment","text":"<p>Create and activate a Python virtual environment with the required Python version:</p>  uv (Linux/macOS) uv (Windows) Conda <pre><code># Create virtual environment with Python 3.12\nuv venv --python=3.12\n\n# Activate the virtual environment\nsource .venv/bin/activate\n</code></pre> <pre><code># Create virtual environment with Python 3.12\nuv venv --python=3.12\n\n# Activate the virtual environment\n.venv\\Scripts\\activate\n</code></pre> <pre><code># Create a new conda environment with Python 3.12\nconda create -n lean-server python=3.12\nconda activate lean-server\n</code></pre>"},{"location":"server/source/#3-install-server-package","title":"3. Install Server Package","text":"<p>Install the server package in editable mode to enable development:</p>  uv Conda <pre><code># Install the server package with all dependencies\nuv pip install -e packages/server\n</code></pre> <pre><code># Install the server package with all dependencies\npython -m pip install -e packages/server\n</code></pre>"},{"location":"server/source/#4-build-lean-dependencies","title":"4. Build Lean Dependencies","text":"<p>Build the Lean workspace and install required mathematical libraries:</p> <pre><code># Navigate to the Lean playground\ncd playground\n\n# Build all Lean dependencies (this may take several minutes)\nlake build\n\n# Return to the project root\ncd ..\n</code></pre> <p>Build Time</p> <p>The initial build process downloads and compiles Mathlib4 and other dependencies, which can take 10-30 minutes depending on your system.</p> <p>Customize Lean Dependencies</p> <p>You can customize the Lean dependencies by modifying the <code>lean-runner/playground/lakefile.toml</code> file, or completely replace the <code>lean-runner/playground</code> directory with your own Lean workspace.</p>"},{"location":"server/source/#running-the-server","title":"Running the Server","text":""},{"location":"server/source/#basic-server-startup","title":"Basic Server Startup","text":"<p>Start the server with default settings:</p> <pre><code># Ensure virtual environment is activated\nsource .venv/bin/activate\n\n# Start the server\nlean-server --port=8888 --concurrency=32\n</code></pre>"},{"location":"server/source/#command-line-options","title":"Command Line Options","text":"<p>The <code>lean-server</code> command supports the following options:</p> Option Default Description <code>--host</code> <code>127.0.0.1</code> Host address to bind to <code>--port</code> <code>8000</code> Port number to listen on <code>--concurrency</code> <code>10</code> Maximum number of concurrent proof verifications <code>--config</code> <code>config.yaml</code> Path to configuration file <code>--log-level</code> <code>INFO</code> Logging level (DEBUG, INFO, WARNING, ERROR) <p>Example Configurations</p> Local DevelopmentProduction DeploymentHigh-Performance Setup <pre><code>lean-server --host=127.0.0.1 --port=8000 --reload --log-level=DEBUG\n</code></pre> <p>Features:</p> <ul> <li>Local access only</li> <li>Auto-reload on code changes</li> <li>Detailed debug logging</li> <li>Good for development and testing</li> </ul> <pre><code>lean-server --host=0.0.0.0 --port=8000 --concurrency=32--log-level=INFO\n</code></pre> <p>Features:</p> <ul> <li>External access enabled</li> <li>Moderate concurrency</li> <li>Standard logging</li> <li>Balanced performance</li> </ul> <pre><code>lean-server --host=0.0.0.0 --port=8000 --concurrency=128 --log-level=WARNING\n</code></pre> <p>Features:</p> <ul> <li>Maximum concurrency</li> <li>Minimal logging overhead</li> <li>Optimized for throughput</li> <li>Requires sufficient system resources</li> </ul>"},{"location":"server/source/#verify-installation","title":"Verify Installation","text":"<p>Test that the server is working correctly:</p>"},{"location":"server/source/#1-check-server-status","title":"1. Check Server Status","text":"Using cURLUsing BrowserUsing Python requests <pre><code># In one terminal, start the server\nlean-server --host=0.0.0.0 --port=8000\n\n# In another terminal, test the health endpoint\ncurl http://localhost:8000/health\n</code></pre> <pre><code># Open your web browser and navigate to:\nhttp://localhost:8000/health\n\n# You should see a JSON response in the browser\n</code></pre> <pre><code>import requests\n\nresponse = requests.get(\"http://localhost:8000/health\")\nprint(response.json())\n</code></pre> <p>Expected response: <pre><code>{\"status\": \"ok\", \"message\": \"Lean Server is running\", \"version\": \"0.0.1\"}\n</code></pre></p>"},{"location":"server/source/#2-test-proof-verification","title":"2. Test Proof Verification","text":"Using cURLUsing Python client <p><pre><code>curl -X POST http://localhost:2333/prove/check \\\n  -F \"proof=import Mathlib.Tactic.NormNum\n      theorem test : 2 + 2 = 4 := by norm_num\"\n</code></pre> <pre><code>{\"success\":true,\"status\":\"finished\",\"result\":{\"env\":0,\"messages\":[]},\"error_message\":null}\n</code></pre> </p> <p><pre><code>from lean_runner import LeanClient\n\nproof = \"\"\"\\\nimport Mathlib.Tactic.NormNum\n\ntheorem test : 1 + 1 = 2 := by norm_num\n\"\"\"\n\nwith LeanClient(base_url=\"http://localhost:8000\") as client:\n    result = client.verify(proof=proof)\n    print(result.model_dump_json(indent=4))\n</code></pre> <pre><code>{\n    \"success\": true,\n    \"status\": \"finished\",\n    \"result\": {\n        \"env\": 0,\n        \"messages\": []\n    },\n    \"error_message\": null\n}\n</code></pre> </p>"},{"location":"server/source/#next-steps","title":"Next Steps","text":"<p>After successful installation:</p> <ol> <li>Read the Client Documentation to learn how to interact with the server</li> <li>Explore the API Documentation for detailed endpoint reference</li> </ol>"}]}